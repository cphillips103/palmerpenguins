---
title: "R Notebook"
output:
  pdf_document: default
  html_notebook: default
---

This is an [R Markdown](http://rmarkdown.rstudio.com) Notebook. When you execute code within the notebook, the results appear beneath the code. 

Try executing this chunk by clicking the *Run* button within the chunk or by placing your cursor inside it and pressing *Ctrl+Shift+Enter*. 

Add a new chunk by clicking the *Insert Chunk* button on the toolbar or by pressing *Ctrl+Alt+I*.

When you save the notebook, an HTML file containing the code and output will be saved alongside it (click the *Preview* button or press *Ctrl+Shift+K* to preview the HTML file).

The preview shows you a rendered HTML copy of the contents of the editor. Consequently, unlike *Knit*, *Preview* does not run any R code chunks. Instead, the output of the chunk when it was last run in the editor is displayed.

```{r}
#Install Remote Package if not already available

#install.packages("remotes")

#Install Palmer Penguin Data
#remotes::install_github("allisonhorst/palmerpenguins")

```

#citation("palmerpenguins")
#> 
#> To cite palmerpenguins in publications use:
#> 
#>   Horst AM, Hill AP, Gorman KB (2020). palmerpenguins: Palmer
#>   Archipelago (Antarctica) penguin data. R package version 0.1.0.
#>   https://allisonhorst.github.io/palmerpenguins/. doi:
#>   10.5281/zenodo.3960218.
#> 
#> A BibTeX entry for LaTeX users is
#> 
#>   @Manual{,
#>     title = {palmerpenguins: Palmer Archipelago (Antarctica) penguin data},
#>     author = {Allison Marie Horst and Alison Presmanes Hill and Kristen B Gorman},
#>     year = {2020},
#>     note = {R package version 0.1.0},
#>     doi = {10.5281/zenodo.3960218},
#>     url = {https://allisonhorst.github.io/palmerpenguins/},
#>   }
#> Also help from Jason Brownlee on machine learning in R February 3, 2016 article


```{r}
#Load Palmer Penguin library and data set
library(palmerpenguins)
data(package = 'palmerpenguins')
```

```{r}
#Load libraries we need for dataframe manipulation and plotting
library(tidyr)
library(dplyr)
library(ggplot2)
library(gridExtra)
library(caret)
library(ellipse)
```

```{r}
library(cluster) 

library(fpc)

library(factoextra)

library(knitr)
```


```{r}
#Initial look at the raw data set
head(penguins)
```

```{r}
#Look at the reduced data set
head(penguins)
```



```{r}
#Look at the data set
str(penguins)
```


```{r}
#Look at number of species in data set
table(penguins$species)
```
```{r}
dim(penguins)
```

```{r}
#Copy data into new datafrme and look at Column names for calculations

df <- penguins
names(df)
```


```{r}
#Initial plot to see which parameters might yield clues about species types
#Species vs body mass
bp<-ggplot(aes(x = species, y = body_mass_g, fill=species), data = df) + geom_boxplot() + coord_flip()

bp + scale_fill_hue(l=40, c=35)
```

```{r}
#Initial plot to see which parameters might yield clues about species types
#Species vs bill length
bp<-ggplot(aes(x = species, y = bill_length_mm, fill=species), data = df) + geom_boxplot() + coord_flip()

bp + scale_fill_hue(l=40, c=35)
```

```{r}
#Initial plot to see which parameters might yield clues about species types
#Species vs bill depth
bp<-ggplot(aes(x = species, y = bill_depth_mm, fill=species), data = df) + geom_boxplot() + coord_flip()

bp + scale_fill_hue(l=40, c=35)
```

```{r}
#Initial plot to see which parameters might yield clues about species types
#Species vs flipper length
bp<-ggplot(aes(x = species, y = flipper_length_mm, fill=species), data = df) + geom_boxplot() + coord_flip()

bp + scale_fill_hue(l=40, c=35)

```





```{r}
#Grid analysis of histograms of the parameers: Lengt and Width and the Petal Length and Width.
# "species"           "island"            "bill_length_mm"    "bill_depth_mm"     "flipper_length_mm"
# "body_mass_g"       "sex"               "year"     

p1 <- ggplot(aes(x = bill_length_mm, fill = species), data = df) +
  geom_histogram()

p2 <- ggplot(aes(x = bill_depth_mm, fill = species), data = df) +
   geom_histogram()

p3 <- ggplot(aes(x = flipper_length_mm, fill = species), data = df) + geom_histogram()

p4 <- ggplot(aes(x = body_mass_g, fill = species), data = df) +
   geom_histogram()


grid.arrange(p1, p2, p3, p4, ncol = 2)
```

```{r}
str(penguins)
```

```{r}
ggplot(penguins, aes(x = island, fill = species)) +
  geom_bar(alpha = 0.8) +
  scale_fill_manual(values = c("darkorange","purple","cyan4"),
                    guide = FALSE) +
  theme_minimal() +
  facet_wrap(~species, ncol = 1) +
  coord_flip()


```


```{r}
penguins %>%
  select(species, body_mass_g, ends_with("_mm")) %>%
  GGally::ggpairs(aes(color = species)) +
  scale_colour_manual(values = c("darkorange","purple","cyan4")) +
  scale_fill_manual(values = c("darkorange","purple","cyan4"))
```

```{r}

#Variables used in clustering "bill_length_mm"  "bill_depth_mm" "flipper_length_mm" "body_mass_g"

set.seed(20)
data_for_clustering <- df


data_for_clustering_no_na <- drop_na(data_for_clustering)

#kmeans data clustering partitioning (assuming 3 centers or clusters).

clusters_penguins <- kmeans(data_for_clustering_no_na[,3:6], nstart = 20, centers = 3)

plotcluster(data_for_clustering_no_na[,3:6], clusters_penguins$cluster, color = TRUE, shade = TRUE)

penguins_no_na <- drop_na(penguins)

table(clusters_penguins$cluster, penguins_no_na$species)


```
#Modeling Work
#Goal is to determine if a model can be built to predict the species of penguin
#based on measurements

```{r}
#Create a Validation Dataset
set.seed(3456)
validation_index <- createDataPartition(data_for_clustering_no_na$species, p=0.80, list=FALSE)
# select 20% of the data for validation
validation <- data_for_clustering_no_na[-validation_index,]
# use the remaining 80% of data to training and testing the models
data_for_clustering_no_na <- data_for_clustering_no_na[validation_index,]

```

```{r}
#Summary of the data set
dim(data_for_clustering_no_na)
```

```{r}
# list types for each attribute
sapply(data_for_clustering_no_na, class)
```

```{r}
# take a peek at the first 5 rows of the data
head(data_for_clustering_no_na)
```


```{r}

2
# list the levels for the class
levels(data_for_clustering_no_na$species)
```
```{r}

# summarize the class distribution
percentage <- prop.table(table(data_for_clustering_no_na$species)) * 100
cbind(freq=table(data_for_clustering_no_na$species), percentage=percentage)

```

```{r}
# summarize attribute distributions
summary(data_for_clustering_no_na)
```

```{r}
#Visualize Data set


# split input and output
x <- data_for_clustering_no_na[,3:6]
y <- data_for_clustering_no_na[,1]


```

```{r}
# barplot for class breakdown
plot(y)
```

```{r}

# scatterplot matrix
featurePlot(x=x, y=y$species, plot="ellipse")
```

```{r}
# box and whisker plots for each attribute
featurePlot(x=x, y=y$species, plot="box")
```

```{r}

1
2
3
# density plots for each attribute by class value
scales <- list(x=list(relation="free"), y=list(relation="free"))
featurePlot(x=x, y=y$species, plot="density", scales=scales)
```

```{r}
#Evaluate Some Algorithms

# Run algorithms using 10-fold cross validation
control <- trainControl(method="cv", number=10, savePredictions = TRUE)
metric <- "Accuracy"


```

```{r}

# a) linear algorithms
set.seed(7)
fit.lda <- train(species~., data=data_for_clustering_no_na, method="lda", metric=metric, trControl=control)
# b) nonlinear algorithms
# CART
set.seed(7)
fit.cart <- train(species~., data=data_for_clustering_no_na, method="rpart", metric=metric, trControl=control)
# kNN
set.seed(7)
fit.knn <- train(species~., data=data_for_clustering_no_na, method="knn", metric=metric, trControl=control)
# c) advanced algorithms
# SVM
set.seed(7)
fit.svm <- train(species~., data=data_for_clustering_no_na, method="svmRadial", metric=metric, trControl=control)
# Random Forest
set.seed(7)
fit.rf <- train(species~., data=data_for_clustering_no_na, method="rf", metric=metric, trControl=control)
```

```{r}
# summarize accuracy of models
results <- resamples(list(lda=fit.lda, cart=fit.cart, knn=fit.knn, svm=fit.svm, rf=fit.rf))
summary(results)
```
```{r}

# compare accuracy of models
dotplot(results)
```

```{r}
# Summarize Best Model
print(fit.svm)

```

```{r}

# estimate skill of best model on the validation dataset
predictions <- predict(fit.svm, validation)
confusionMatrix(predictions, validation$species)

```

